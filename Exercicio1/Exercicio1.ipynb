{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT66jwgGFWT8"
   },
   "source": [
    "# Exercício 1\n",
    "\n",
    "Enunciado do exercício da semana:\n",
    "\n",
    "1. Usar o BM25 implementado pelo pyserini para buscar queries no TREC-DL 2020 ([Documentação de referência](https://github.com/castorini/pyserini/blob/master/docs/experiments-msmarco-passage.md))\n",
    "2. Implementar um buscador booleano/bag-of-words.\n",
    "3. Implementar um buscador com TF-IDF\n",
    "4. Avaliar implementações 1, 2, e 3 no TREC-DL 2020 e calcular o nDCG@10\n",
    "\n",
    "Nos itens 2 e 3: (i) Fazer uma implementação que suporta buscar eficientemente milhões de documentos e (ii) Não se pode usar bibliotecas como sklearn, que já implementam o BoW e TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B32kQjQzpTuH"
   },
   "source": [
    "## Instalação de Pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N95r-svSoStI"
   },
   "outputs": [],
   "source": [
    "# !pip install pyserini\n",
    "# !pip install faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NxMfCAdJpaB8",
    "outputId": "f35ddf7d-ecfb-4846-a143-b4bb86b69ccd"
   },
   "outputs": [],
   "source": [
    "  ### Used only to run on Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "# Change de path to your drive\n",
    "# base_path = \"gdrive/MyDrive/Colab_Notebooks/P_IA368DD_2023S1/Exercicio1/\"\n",
    "base_path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLYf5apYCtPe",
    "outputId": "6a37ea0b-cc77-4dab-b83a-fb4c36013f37"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG2443rNrdTu"
   },
   "source": [
    "## Download dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtsHCbkLqUEl"
   },
   "outputs": [],
   "source": [
    "!wget https://msmarco.blob.core.windows.net/msmarcoranking/collectionandqueries.tar.gz -P \"{base_path}data/\"\n",
    "!tar xvfz \"{base_path}data/collectionandqueries.tar.gz\" -C \"{base_path}data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4lNZdOnGBE6"
   },
   "source": [
    "Converte os arquivos de TSV para JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuvYMnpQFscW"
   },
   "source": [
    "## Instalação do pyserini e pyserini tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UHPNqA1s4qc"
   },
   "outputs": [],
   "source": [
    "os.makedirs(f\"{base_path}tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "647r3uSjs6Ss"
   },
   "outputs": [],
   "source": [
    "!wget -q https://github.com/castorini/anserini-tools/archive/refs/heads/master.zip -O \"{base_path}tools/anserini-tools.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rn-NMh1UFDkT"
   },
   "outputs": [],
   "source": [
    "!unzip -q \"{base_path}tools/anserini-tools.zip\" -d \"{base_path}tools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Vo_pjL4GCI3"
   },
   "outputs": [],
   "source": [
    "!python \"{base_path}tools/anserini-tools-master/scripts/msmarco/convert_collection_to_jsonl.py\" \\\n",
    " --collection-path \"{base_path}data/collection.tsv\" \\\n",
    " --output-folder \"{base_path}data/collection_jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZmAtu1S-IWg3"
   },
   "outputs": [],
   "source": [
    "!wget -q https://github.com/castorini/pyserini/archive/refs/heads/master.zip -O pyserini.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKhWm0GvIfyW"
   },
   "outputs": [],
   "source": [
    "!unzip -q pyserini.zip -d  {base_path}/pyserini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_kg9rBbFxp7"
   },
   "source": [
    "## Cria os índices dos documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NOy9W25gFm6n"
   },
   "outputs": [],
   "source": [
    "!python -m pyserini.index.lucene \\\n",
    "  --collection JsonCollection \\\n",
    "  --input \"{base_path}data/collection_jsonl\" \\\n",
    "  --index \"{base_path}data/indexes/lucene-index-msmarco-passage\" \\\n",
    "  --generator DefaultLuceneDocumentGenerator \\\n",
    "  --threads 9 \\\n",
    "  --storePositions --storeDocvectors --storeRaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rjHsciJJoHR",
    "outputId": "0cbcc8ab-dec5-4a62-d6c7-ac776b110b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048585\twhat is paula deen's brother\n",
      "2\t Androgen receptor define\n",
      "524332\ttreating tension headaches without medication\n",
      "1048642\twhat is paranoid sc\n",
      "524447\ttreatment of varicose veins in legs\n",
      "786674\twhat is prime rate in canada\n",
      "1048876\twho plays young dr mallard on ncis\n",
      "1048917\twhat is operating system misconfiguration\n",
      "786786\twhat is priority pass\n",
      "524699\ttricare service number\n"
     ]
    }
   ],
   "source": [
    "!head \"{base_path}tools/anserini-tools-master/topics-and-qrels/topics.msmarco-passage.dev-subset.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4Znw1JAOQls",
    "outputId": "3b672a39-ba28-4a64-a362-4cea2286d296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:16:08.415318: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 14:16:09.663973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-04 14:16:09.664090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-04 14:16:09.664106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using pre-defined topic order for msmarco-passage-dev-subset\n",
      "Setting BM25 parameters: k1=0.82, b=0.68\n",
      "Running msmarco-passage-dev-subset topics, saving to runs/run.msmarco-passage.bm25tuned.txt...\n",
      "100% 6980/6980 [14:02<00:00,  8.28it/s]\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.search.lucene \\\n",
    "  --index \"{base_path}data/indexes/lucene-index-msmarco-passage\" \\\n",
    "  --topics msmarco-passage-dev-subset \\\n",
    "  --output runs/run.msmarco-passage.bm25tuned.txt \\\n",
    "  --output-format msmarco \\\n",
    "  --hits 1000 \\\n",
    "  --bm25 --k1 0.82 --b 0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxeNnISiO7qY",
    "outputId": "a5044d65-9f64-49cc-b07f-ab48c70f9ce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####################\n",
      "MRR @10: 0.18741227770955546\n",
      "QueriesRanked: 6980\n",
      "#####################\n"
     ]
    }
   ],
   "source": [
    "!python \"{base_path}tools/anserini-tools-master/scripts/msmarco/msmarco_passage_eval.py\" \\\n",
    "   \"{base_path}tools/anserini-tools-master/topics-and-qrels/qrels.msmarco-passage.dev-subset.txt\" runs/run.msmarco-passage.bm25tuned.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viRlhwNazduZ"
   },
   "source": [
    "Avaliação oficial TREC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uN89aR45xApd",
    "outputId": "83f3b55a-64d0-41bd-faf0-a5c9a7191590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python -m pyserini.eval.convert_msmarco_run_to_trec_run \\\n",
    "   --input runs/run.msmarco-passage.bm25tuned.txt \\\n",
    "   --output runs/run.msmarco-passage.bm25tuned.trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYEd1UhiztPB",
    "outputId": "cb3fd7b2-9521-47c2-b4d9-0fa7db074db4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "!python {base_path}tools/anserini-tools-master/scripts/msmarco/convert_msmarco_to_trec_qrels.py \\\n",
    "   --input {base_path}tools/anserini-tools-master/topics-and-qrels/qrels.msmarco-passage.dev-subset.txt \\\n",
    "   --output {base_path}data/qrels.dev.small.trec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ahG1nvP50EWP",
    "outputId": "e4cebd2f-2e73-45c4-b916-30cda4a67ad0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-04 15:03:24.397980: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 15:03:27.017487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-04 15:03:27.017795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-04 15:03:27.017831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "jtreceval-0.0.5-jar-with-dependencies.jar: 1.79MB [00:00, 5.37MB/s]                \n",
      "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-mrecall.1000', '-mmap', 'gdrive/MyDrive/Colab_Notebooks/P_IA368DD_2023S1/Exercicio1//data/qrels.dev.small.trec', 'runs/run.msmarco-passage.bm25tuned.trec']\n",
      "Results:\n",
      "map                   \tall\t0.1957\n",
      "recall_1000           \tall\t0.8573\n"
     ]
    }
   ],
   "source": [
    "!python {base_path}pyserini/pyserini-master/pyserini/eval/trec_eval.py -c -mrecall.1000 -mmap \\\n",
    "   {base_path}/data/qrels.dev.small.trec runs/run.msmarco-passage.bm25tuned.trec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0eQAUBZJy9w"
   },
   "source": [
    "Métrica ndcg@10 pelo pyserini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtvWRu1EGTsq",
    "outputId": "bb4a97ad-ee7b-4c19-8a99-13a47d670019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-04 15:05:36.350189: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-04 15:05:38.050326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-04 15:05:38.050501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-03-04 15:05:38.050547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
      "Skipping download.\n",
      "Running command: ['java', '-jar', '/root/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-mndcg_cut.10', 'gdrive/MyDrive/Colab_Notebooks/P_IA368DD_2023S1/Exercicio1//data/qrels.dev.small.trec', 'runs/run.msmarco-passage.bm25tuned.trec']\n",
      "Results:\n",
      "ndcg_cut_10           \tall\t0.2340\n"
     ]
    }
   ],
   "source": [
    "!python {base_path}pyserini/pyserini-master/pyserini/eval/trec_eval.py -c -mndcg_cut.10 \\\n",
    "   {base_path}/data/qrels.dev.small.trec runs/run.msmarco-passage.bm25tuned.trec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmCsSVKS-z49"
   },
   "source": [
    "## Buscador Bag of Words\n",
    "\n",
    "Referência: https://colab.research.google.com/drive/1hELJYqsvUyja9HPeDzc9FU8okqdIjODE?usp=sharing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QeO7uGGXKL-9"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle\n",
    "import array\n",
    "from pyserini.analysis import Analyzer, get_lucene_analyzer\n",
    "from pyserini.search import get_topics\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R4XCVv9fH5s",
    "outputId": "0aa27e47-72a4-4642-cdb8-74a2b8bbcc11"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/manny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(txt):\n",
    "    \"\"\"\n",
    "    Return a preprocessed tokenized text.\n",
    "\n",
    "    Args:\n",
    "        txt (str): original text to process\n",
    "\n",
    "    Returns:\n",
    "        Return a preprocessed tokenized text.\n",
    "    \"\"\"\n",
    "    txt = txt.lower()\n",
    "    tokens = word_tokenize(txt)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word.isalpha()]\n",
    "    tokens = set(tokens).difference(stop_words)\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dwXOiShkZA0H"
   },
   "outputs": [],
   "source": [
    "def generate_index():\n",
    "    tokenizer = Analyzer(get_lucene_analyzer(stemmer='porter'))\n",
    "    num_lines = sum(1 for line in open(f'{base_path}data/collection.tsv', 'r'))\n",
    "    index = {}\n",
    "    doc_size = {}\n",
    "\n",
    "    with open(f'{base_path}data/collection.tsv', encoding='utf-8') as f:\n",
    "        for idx, line in tqdm(enumerate(f), total=num_lines):\n",
    "            doc_id, text = line.rstrip().split('\\t')\n",
    "            tokens = preprocess_string(text) #tokenizer.analyze(text)\n",
    "\n",
    "            tokens_doc = Counter(tokens)\n",
    "            for token, n_ocorrencias in tokens_doc.items():\n",
    "                index.setdefault(token, {\"doc_id\": array.array(\"L\", []), \"n_ocurr\": array.array(\"L\", [])})[\n",
    "                    'doc_id'].append(int(doc_id))\n",
    "                index.setdefault(token, {\"doc_id\": array.array(\"L\", []), \"n_ocurr\": array.array(\"L\", [])})[\n",
    "                    'n_ocurr'].append(n_ocorrencias)\n",
    "\n",
    "            doc_size[int(doc_id)] = len(tokens)\n",
    "\n",
    "    with open(f'{base_path}data/inverted_index_nltk.pickle', 'wb') as f:\n",
    "        pickle.dump(index, f)\n",
    "\n",
    "    del index\n",
    "    gc.collect()\n",
    "\n",
    "    with open(f'{base_path}data/doc_size_nltk.pickle', 'wb') as f:\n",
    "        pickle.dump(doc_size, f)\n",
    "\n",
    "    del doc_size\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lu8FFvi34ujx"
   },
   "outputs": [],
   "source": [
    "def search_bow(query, tokenizer, stop_words):\n",
    "    stopwords_nltk = set(stop_words)\n",
    "\n",
    "#     tokens = tokenizer.analyze(query)\n",
    "#     tokens = set(tokens).difference(stopwords_nltk)\n",
    "    tokens = preprocess_string(query)\n",
    "\n",
    "    # Se não tem token para ser pesquisado, retorna conjunto vazio\n",
    "    if (len(tokens) == 0):\n",
    "        return []\n",
    "\n",
    "    docs_score = {}\n",
    "\n",
    "    for token in tokens:\n",
    "\n",
    "        # Busca somente os tokens encontrados\n",
    "        if token in index:\n",
    "            docs_found = index[token]['doc_id']\n",
    "            n_ocurr_doc = index[token]['n_ocurr']\n",
    "\n",
    "            for id_doc, n_ocurr in zip(docs_found, n_ocurr_doc):\n",
    "                docs_score[id_doc] = docs_score.get(id_doc, 0) + n_ocurr\n",
    "\n",
    "    docs_com_score = list(docs_score.items())\n",
    "\n",
    "    # Ordena do mais relevante para o menos relevante\n",
    "    return sorted(docs_com_score, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stemmer = nltk.stem.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2794baf1767642b8bdac90881e748253",
      "b61c409ff61643e9af19282a7481ebaa",
      "219b8e2ed1ca4fb8bcf61f54db622c3f",
      "a4d15c8d27c34cc1b4e31100231436e9",
      "c458c33149fa43419f4ce11af6176b90",
      "1b89ae6fc4a945f38849652ae9c8799d",
      "9bce75d5c89940148a2710f60411d373",
      "93ca8589cede4f02a75eacd156120c2f",
      "0541120408df42da9f3e6c1ee013312f",
      "34275e88ea674168a4e705afd759fed2",
      "4c75edd2bb2342479c16cd56568d7f23"
     ]
    },
    "id": "L73Rr1l7fBPg",
    "outputId": "3016e875-e233-4105-b776-65b8d25dfc9c"
   },
   "outputs": [],
   "source": [
    "# Carregar/gerar o índice e dicionário com o totalizador de tokens por documento\n",
    "# path_index = f'{base_path}data/inverted_index.pickle'\n",
    "# path_doc_size = f'{base_path}data/doc_size.pickle'\n",
    "\n",
    "path_index = f'{base_path}data/inverted_index_nltk.pickle'\n",
    "path_doc_size = f'{base_path}data/doc_size_nltk.pickle'\n",
    "\n",
    "if os.path.exists(path_index):\n",
    "    with open(path_index, 'rb') as f:\n",
    "        index = pickle.load(f)\n",
    "\n",
    "    with open(path_doc_size, 'rb') as f:\n",
    "        doc_size = pickle.load(f)\n",
    "else:\n",
    "    generate_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "h3S128wCaj7e"
   },
   "outputs": [],
   "source": [
    "tokenizer = Analyzer(get_lucene_analyzer(stemmer='porter'))\n",
    "stop_words = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "36_X7qoh3zRo"
   },
   "outputs": [],
   "source": [
    "topics = get_topics('dl20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-mYbiOPfJee",
    "outputId": "e8a1af7e-4608-481c-d261-50e495ab7a90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: who sings monk theme song\n",
      "Tokens da query: ['who', 'sing', 'monk', 'theme', 'song']\n",
      "[(10076, 3), (10083, 3), (11193, 3), (28358, 3), (28359, 3), (49533, 3), (58138, 3), (58139, 3), (69817, 3), (242238, 3)]\n"
     ]
    }
   ],
   "source": [
    "query = topics[1051399][\"title\"]\n",
    "print(f'Query: {query}')\n",
    "print(f'Tokens da query: {tokenizer.analyze(query)}')\n",
    "resultado = search_bow(query, tokenizer, stop_words)\n",
    "print(resultado[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZDNFVxjvbS1W"
   },
   "outputs": [],
   "source": [
    "def run_all_queries_search_bow(file_name, topics):\n",
    "    with open(file_name, 'w') as file:\n",
    "        for id in tqdm(topics):\n",
    "            query = topics[id]['title']\n",
    "            hits = search_bow(query, tokenizer, stop_words)\n",
    "            for i in range(0, min(len(hits), 30)):\n",
    "                _ = file.write('{} Q0 {} {} {:.6f} '.format(id, hits[i][0], i + 1, hits[i][1]) + \"bow\" + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217,
     "referenced_widgets": [
      "84ba2b1acce54519bd31ea7e5f38e384",
      "0a6830b86e1240c7a1de2a5d8481952b",
      "914bc7bf2ca54afaa6b9255f6ebcb25f",
      "3ccd7865c020483bb4654a09583dad0f",
      "05c7cd43155a4316b4b71fdf169fb6a9",
      "2356fa193f764e2d8532fdec5437f63b",
      "49fea0f0134945dfad83c636d78bd2c5",
      "31bebe50bc554c669866ddc45d83cde8",
      "c1ca7d71ed1147df922276a1998926be",
      "8b83d9be386040bfaefffacb13ece6dc",
      "191893ac95df4b05bb2688b285c9bdef"
     ]
    },
    "id": "Lb9EFulebmIb",
    "outputId": "2c8746f7-b60d-4572-b800-c22a7c075443"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec17128156148c3bb22e33014f2dc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /Users/manny/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "/Users/manny/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
      "Skipping download.\n",
      "Running command: ['java', '-jar', '/Users/manny/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/Users/manny/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-search-bow_nltk.dl20.txt']\n",
      "Results:\n",
      "ndcg_cut_10           \tall\t0.3151\n"
     ]
    }
   ],
   "source": [
    "run_all_queries_search_bow('run-search-bow_nltk.dl20.txt', topics)\n",
    "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run-search-bow_nltk.dl20.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYsq0T-m9Ob3"
   },
   "source": [
    "## Buscador TF-IDF\n",
    "\n",
    "Referência: https://colab.research.google.com/drive/1hELJYqsvUyja9HPeDzc9FU8okqdIjODE?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "hxGR-1vy9QZJ"
   },
   "outputs": [],
   "source": [
    "class TfidfSearcher:\n",
    "    def __init__(self, inverted_index, doc_size, stop_words):\n",
    "        self.inverted_index = inverted_index\n",
    "        self.total_docs = len(doc_size)\n",
    "        self.tokenizer = Analyzer(get_lucene_analyzer(stemmer='porter'))\n",
    "        self.stop_words = stop_words\n",
    "\n",
    "    def idf(self, token):\n",
    "        if 'idf' not in self.inverted_index[token]:\n",
    "            docs_with_token = len(self.inverted_index[token]['doc_id'])\n",
    "            idf = np.log10(self.total_docs / docs_with_token)\n",
    "            self.inverted_index[token]['idf'] = idf\n",
    "\n",
    "        return self.inverted_index[token]['idf']\n",
    "\n",
    "    def tf_idf(self, doc_id, freq, token):\n",
    "        if 'idf' not in self.inverted_index[token]:\n",
    "            self.idf(token)\n",
    "\n",
    "        doc_size_in_tokens = doc_size[doc_id]\n",
    "        tf = freq / doc_size_in_tokens\n",
    "\n",
    "        return tf * self.inverted_index[token]['idf']\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "#         tokens = tokenizer.analyze(text)\n",
    "#         tokens = set(tokens).difference(self.stop_words)\n",
    "        tokens = preprocess_string(text)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    def vec_query_tf(self, tokenized_query):\n",
    "        query_counter = Counter(tokenized_query)\n",
    "\n",
    "    def query(self, query):\n",
    "#         tokenized_query = self._tokenize(query)\n",
    "        tokenized_query = preprocess_string(query)\n",
    "\n",
    "        scores = {}\n",
    "\n",
    "        for token in tokenized_query:\n",
    "            docs_with_tokens = self.inverted_index[token]['doc_id']\n",
    "            freqs = self.inverted_index[token]['n_ocurr']\n",
    "\n",
    "            for doc_id, freq in zip(docs_with_tokens, freqs):\n",
    "                if doc_id not in scores:\n",
    "                    scores[doc_id] = self.tf_idf(doc_id, freq, token)\n",
    "                else:\n",
    "                    scores[doc_id] += self.tf_idf(doc_id, freq, token)\n",
    "\n",
    "        return sorted(scores.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "RGB6uOM9baSL"
   },
   "outputs": [],
   "source": [
    "searcher = TfidfSearcher(index, doc_size, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "-8abSVXNbVGs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: who sings monk theme song\n",
      "Tokens da query: ['who', 'sing', 'monk', 'theme', 'song']\n",
      "[(1989028, 1.108891170783285), (69813, 1.0672879788485814), (69818, 1.0672879788485814), (4359243, 1.0008311730685004), (2319136, 0.8929669447961761), (2866978, 0.8536729666367812), (5329142, 0.8536729666367812), (3466639, 0.8340259775570836), (3943227, 0.8034992723261856), (4245382, 0.768305669973103)]\n"
     ]
    }
   ],
   "source": [
    "query = topics[1051399][\"title\"]\n",
    "print(f'Query: {query}')\n",
    "print(f'Tokens da query: {tokenizer.analyze(query)}')\n",
    "resultado = searcher.query(query)\n",
    "print(resultado[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all queries in topics\n",
    "def run_all_queries(file, topics, searcher):\n",
    "    with open(file, 'w') as runfile:\n",
    "        cnt = 0\n",
    "        for id in tqdm(topics):\n",
    "            query = topics[id]['title']\n",
    "            hits = searcher.query(query)\n",
    "            for i in range(0, min(len(hits), 1000)):\n",
    "                _ = runfile.write('{} Q0 {} {} {:.6f} TFIDF\\n'.format(id, hits[i][0], i+1, hits[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae4d12172e6477db267e4a4a625f08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://search.maven.org/remotecontent?filepath=uk/ac/gla/dcs/terrierteam/jtreceval/0.0.5/jtreceval-0.0.5-jar-with-dependencies.jar to /Users/manny/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar...\n",
      "/Users/manny/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar already exists!\n",
      "Skipping download.\n",
      "Running command: ['java', '-jar', '/Users/manny/.cache/pyserini/eval/jtreceval-0.0.5-jar-with-dependencies.jar', '-c', '-m', 'ndcg_cut.10', '/Users/manny/.cache/pyserini/topics-and-qrels/qrels.dl20-passage.txt', 'run-search-tfidf_nltk.dl20.txt']\n",
      "Results:\n",
      "ndcg_cut_10           \tall\t0.1050\n"
     ]
    }
   ],
   "source": [
    "run_all_queries('run-search-tfidf_nltk.dl20.txt', topics, searcher)\n",
    "!python -m pyserini.eval.trec_eval -c -m ndcg_cut.10 dl20-passage run-search-tfidf_nltk.dl20.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0541120408df42da9f3e6c1ee013312f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "05c7cd43155a4316b4b71fdf169fb6a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0a6830b86e1240c7a1de2a5d8481952b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2356fa193f764e2d8532fdec5437f63b",
      "placeholder": "​",
      "style": "IPY_MODEL_49fea0f0134945dfad83c636d78bd2c5",
      "value": "100%"
     }
    },
    "191893ac95df4b05bb2688b285c9bdef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b89ae6fc4a945f38849652ae9c8799d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "219b8e2ed1ca4fb8bcf61f54db622c3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93ca8589cede4f02a75eacd156120c2f",
      "max": 8841823,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0541120408df42da9f3e6c1ee013312f",
      "value": 1896122
     }
    },
    "2356fa193f764e2d8532fdec5437f63b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2794baf1767642b8bdac90881e748253": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b61c409ff61643e9af19282a7481ebaa",
       "IPY_MODEL_219b8e2ed1ca4fb8bcf61f54db622c3f",
       "IPY_MODEL_a4d15c8d27c34cc1b4e31100231436e9"
      ],
      "layout": "IPY_MODEL_c458c33149fa43419f4ce11af6176b90"
     }
    },
    "31bebe50bc554c669866ddc45d83cde8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34275e88ea674168a4e705afd759fed2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ccd7865c020483bb4654a09583dad0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b83d9be386040bfaefffacb13ece6dc",
      "placeholder": "​",
      "style": "IPY_MODEL_191893ac95df4b05bb2688b285c9bdef",
      "value": " 200/200 [02:14&lt;00:00,  1.42it/s]"
     }
    },
    "49fea0f0134945dfad83c636d78bd2c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4c75edd2bb2342479c16cd56568d7f23": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84ba2b1acce54519bd31ea7e5f38e384": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a6830b86e1240c7a1de2a5d8481952b",
       "IPY_MODEL_914bc7bf2ca54afaa6b9255f6ebcb25f",
       "IPY_MODEL_3ccd7865c020483bb4654a09583dad0f"
      ],
      "layout": "IPY_MODEL_05c7cd43155a4316b4b71fdf169fb6a9"
     }
    },
    "8b83d9be386040bfaefffacb13ece6dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "914bc7bf2ca54afaa6b9255f6ebcb25f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31bebe50bc554c669866ddc45d83cde8",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c1ca7d71ed1147df922276a1998926be",
      "value": 200
     }
    },
    "93ca8589cede4f02a75eacd156120c2f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bce75d5c89940148a2710f60411d373": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a4d15c8d27c34cc1b4e31100231436e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34275e88ea674168a4e705afd759fed2",
      "placeholder": "​",
      "style": "IPY_MODEL_4c75edd2bb2342479c16cd56568d7f23",
      "value": " 1896122/8841823 [09:26&lt;49:49, 2323.72it/s]"
     }
    },
    "b61c409ff61643e9af19282a7481ebaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b89ae6fc4a945f38849652ae9c8799d",
      "placeholder": "​",
      "style": "IPY_MODEL_9bce75d5c89940148a2710f60411d373",
      "value": " 21%"
     }
    },
    "c1ca7d71ed1147df922276a1998926be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c458c33149fa43419f4ce11af6176b90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
