{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1eabcb",
   "metadata": {},
   "source": [
    "## Exercicío 10\n",
    "\n",
    "Implementar um pipeline multidoc QA: \n",
    "\n",
    "* Dado uma pergunta do usuário, buscamos em uma grande coleção as passagens mais relevantes e as enviamos para um sistema agregador, que irá gerar uma resposta final.\n",
    "* Avaliar no dataset do IIRC\n",
    "* Métrica principal: F1\n",
    "* Limitar dataset de teste para 50 exemplos para economizar.\n",
    "* Usar o gpt-3.5-turbo como modelo agregador. Usar vicuna-13B como alternativa open-source:\n",
    "    * https://huggingface.co/helloollel/vicuna-13b \n",
    "    * https://chat.lmsys.org/ \n",
    "* Dicas:\n",
    "    * Se inspirar no pipeline do Visconde: https://github.com/neuralmind-ai/visconde "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36dfabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import InvalidRequestError\n",
    "from pyserini.search import LuceneSearcher\n",
    "from sentence_transformers import CrossEncoder\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import openai\n",
    "import time\n",
    "import json\n",
    "import argparse\n",
    "import collections\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b583245",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af09514e",
   "metadata": {},
   "source": [
    "### Indexing BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2fdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = json.load(open(f\"{base_path}/data/iirc_test.json\", \"r\"))\n",
    "context_articles = json.load(open(f\"{base_path}/data/context_articles.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a980fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "all_titles = []\n",
    "\n",
    "for item in tqdm(test_set):\n",
    "    if item['title'].lower() not in all_titles:\n",
    "        documents.append({\n",
    "                \"title\": item['title'],\n",
    "                \"content\": item[\"text\"]\n",
    "            }\n",
    "        )\n",
    "        all_titles.append(item['title'].lower())\n",
    "        \n",
    "    for link in item[\"links\"]:\n",
    "        if link['target'].lower() in context_articles and link['target'].lower() not in all_titles:\n",
    "            documents.append({\n",
    "                \"title\": link['target'],\n",
    "                \"content\": context_articles[link['target'].lower()]\n",
    "            })\n",
    "            all_titles.append(link['target'].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec95c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "nlp.create_pipe(\"sentencizer\")\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "stride = 2\n",
    "max_length = 3\n",
    "\n",
    "def window(documents, stride=2, max_length=3):\n",
    "    treated_documents = []\n",
    "\n",
    "    for j,document in enumerate(tqdm(documents)):\n",
    "        doc_text = document['content']\n",
    "        doc = nlp(doc_text[:10000])\n",
    "        sentences = [sent.text.strip() for sent in doc.sents]\n",
    "        for i in range(0, len(sentences), stride):\n",
    "            segment = ' '.join(sentences[i:i + max_length])\n",
    "            treated_documents.append({\n",
    "                \"title\": document['title'],\n",
    "                \"contents\": document['title']+\". \"+segment,\n",
    "                \"segment\": segment\n",
    "            })\n",
    "            if i + max_length >= len(sentences):\n",
    "                break\n",
    "    return treated_documents\n",
    "\n",
    "treated_documents = window(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2201637",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(f\"{base_path}/data/iirc_indices/contents.jsonl\",'w')\n",
    "\n",
    "for i, doc in enumerate(treated_documents):\n",
    "    doc['id'] = i\n",
    "    if doc['segment'] != \"\":\n",
    "        f.write(json.dumps(doc)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b55ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pyserini.index -collection JsonCollection -generator DefaultLuceneDocumentGenerator -threads 1 -input data/iirc_indices -index data/iirc_index -storeRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d923b96",
   "metadata": {},
   "source": [
    "### Generate Evidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d09fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = json.load(open(f\"{base_path}/data/samples_test.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3558cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = LuceneSearcher(f\"{base_path}/data/iirc_index\")\n",
    "model_id = \"cross-encoder/ms-marco-MiniLM-L-6-v2\"\n",
    "model = CrossEncoder(model_id, max_length=512, num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad102dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_samples():\n",
    "    test = json.load(open(f\"{base_path}/data/iirc_test.json\"))\n",
    "    random_list = random.sample(range(0, len(test)), 50)\n",
    "    samples = []\n",
    "    all_q = []\n",
    "\n",
    "    for item in test:\n",
    "        for q in item['questions']:\n",
    "            q['text'] = item['text']\n",
    "            q['title'] = item['title']\n",
    "            q['links'] = item['links']\n",
    "            all_q.append(q)\n",
    "        \n",
    "    for i in random_list:\n",
    "        samples.append(all_q[i])\n",
    "    \n",
    "    with open(f\"{base_path}/data/samples_test.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(samples, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a62efa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_with_bm25(query, k=1000):\n",
    "    return searcher.search(query, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ba35ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reranking_cross_encoder(docs, max=1000, batch_size=500):\n",
    "    for i in tqdm(range(0, len(docs), batch_size), leave=False):  # tqdm(docs):\n",
    "        i_end = i + batch_size\n",
    "        i_end = len(docs) if i_end > len(docs) else i_end\n",
    "\n",
    "        batch = docs[i:i_end]\n",
    "\n",
    "        text_pairs = [(sample['question'], sample[\"title\"] + \" \" + sample['text']) for sample in batch]\n",
    "        predictions = model.predict(text_pairs)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for score, result in zip(predictions, batch):\n",
    "            results.append((result, score))\n",
    "\n",
    "    sorted_list = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    return sorted_list[:max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d64f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(item):\n",
    "    temperature = 0\n",
    "    attempts = 1\n",
    "    pattern = \"(?<=Answer:)(.*)$\"\n",
    "\n",
    "    item['responses'] = []\n",
    "    item['completions'] = []\n",
    "    for i in range(attempts):\n",
    "        try:\n",
    "            res = generate(item['system_prompt'], item['prompts'], temperature=temperature)\n",
    "        except InvalidRequestError:\n",
    "            # Reduces the number of prompts by removing the largest one\n",
    "            print(\"Current number of prompts = \", len(item['prompts']))\n",
    "            max_prompt = item['prompts'][0]\n",
    "            max_len = len(item['prompts'][0])\n",
    "            for i, prompt in enumerate(item['prompts']):\n",
    "                if i != 0 and len(prompt) > max_len:\n",
    "                    max_len = len(prompt)\n",
    "                    max_prompt = prompt\n",
    "            item['prompts'].remove(max_prompt)\n",
    "            # Try again\n",
    "            res = generate(item['system_prompt'], item['prompts'], temperature=temperature)\n",
    "\n",
    "        if \"Answer\" not in res:\n",
    "            item['results'] = res\n",
    "            item['responses'].append(res)\n",
    "            item['completions'].append(res)\n",
    "            item[\"asked_twice\"] = True\n",
    "        else:\n",
    "            matches = re.findall(pattern, res)\n",
    "            if len(matches) > 0:\n",
    "                response = matches[0]\n",
    "                item['responses'].append(response)\n",
    "            item['results'] = res\n",
    "            item['completions'].append(res)\n",
    "            item[\"asked_twice\"] = False\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e8d6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline():\n",
    "    test = []\n",
    "    for q in tqdm(test_set):\n",
    "        item_passage = \"\"\n",
    "        for i, c in enumerate(q['context']):\n",
    "            item_passage += \"Document {0}: {1}\\n\\n\".format(i + 1, c['text'])\n",
    "        item_passage += \"{0}\".format(q['question'])\n",
    "\n",
    "        # Fisrt stage\n",
    "        hits = search_with_bm25(item_passage, 100)\n",
    "        docs = []\n",
    "\n",
    "        for hit in hits:\n",
    "            hit = json.loads(hit.raw)\n",
    "            doc = {\n",
    "                \"passage_id\": hit[\"id\"],\n",
    "                \"question\": q[\"question\"],\n",
    "                \"text\": hit[\"contents\"],\n",
    "                \"context\": q[\"context\"],\n",
    "                \"title\": hit[\"title\"],\n",
    "                \"text\": hit[\"contents\"],\n",
    "                \"answer\": q[\"answer\"]\n",
    "            }\n",
    "            docs.append(doc)\n",
    "\n",
    "        # Second stage\n",
    "        docs_reranking = reranking_cross_encoder(docs, 4, 100)\n",
    "\n",
    "        system_prompt = \"For each example, use the documents to create an \\\"Answer\\\" and an \\\"Evidence\\\" to the \\\"Question\\\". Answer \\\"not enough information\\\" when not enough information is provided in the documents.\\n\\n\"\n",
    "        prompts = []\n",
    "        for i, hit_score in enumerate(docs_reranking):\n",
    "            hit = hit_score[0]\n",
    "            prompt = \"Example {0}:\\n\\n\".format(i + 1)\n",
    "            for j, c in enumerate(hit['context']):\n",
    "                if c['passage'] == \"main\":\n",
    "                    text = \"Title: {0}. Content: {1}\".format(hit['title'], c['text'])\n",
    "                else:\n",
    "                    text = \"Title: {0}. Content: {1}\".format(c['passage'], c['text'])\n",
    "                prompt += \"Document {0}: {1}\\n\\n\".format(j + 1, text)\n",
    "            answer = hit['answer']\n",
    "\n",
    "            prompt += \"Question: Based on the above documents, {0}\\n\\nEvidence: {1}\\n\\nAnswer: {2}.\\n\\n\".format(\n",
    "                hit['question'], 'Not found.', answer)\n",
    "\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        prompt = \"Example {0}:\\n\\n\".format(i + 2)\n",
    "\n",
    "        text = \"Title: {0}. Content: {1}\".format(q['title'], q['text'])\n",
    "        prompt += \"Document {0}: {1}\\n\\n\".format(i + 1, text)\n",
    "\n",
    "        prompt += \"Question: Based on the above documents, {0}\\n\\nEvidence:\".format(q['question'])\n",
    "        prompts.append(prompt)\n",
    "\n",
    "        q['prompts'] = prompts\n",
    "        q['system_prompt'] = system_prompt\n",
    "        answers = []\n",
    "        if q['answer']['type'] == \"span\":\n",
    "            at = \", \".join([a['text'] for a in q['answer'][\"answer_spans\"]])\n",
    "            answers.append(at)\n",
    "        elif q['answer']['type'] == \"value\":\n",
    "            at = \"{0} {1}\".format(q['answer']['answer_value'], q['answer']['answer_unit'])\n",
    "            answers.append(at)\n",
    "        elif q['answer']['type'] == \"binary\":\n",
    "            answers.append(q['answer']['answer_value'])\n",
    "        elif q['answer']['type'] == \"none\":\n",
    "            answers.append(\"Not enough information\")\n",
    "        q['clean_answers'] = answers\n",
    "\n",
    "        q = generate_answer(q)\n",
    "\n",
    "        test.append(q)\n",
    "\n",
    "    json.dump(test, open(f\"{base_path}/data/iirc.json\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "287cf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(system_prompt, prompts, temperature=0):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": prompt} for prompt in prompts]\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-3.5-turbo\",\n",
    "        messages = messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    return response[\"choices\"][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9baa9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(s):\n",
    "    \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "\n",
    "    def remove_articles(text):\n",
    "        regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "        return re.sub(regex, ' ', text)\n",
    "\n",
    "    def white_space_fix(text):\n",
    "        return ' '.join(text.split())\n",
    "\n",
    "    def remove_punc(text):\n",
    "        exclude = set(string.punctuation)\n",
    "        return ''.join(ch for ch in text if ch not in exclude)\n",
    "\n",
    "    def lower(text):\n",
    "        return text.lower()\n",
    "\n",
    "    def remove_accents(input_str):\n",
    "        nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "        only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "        return only_ascii.decode(\"utf-8\")\n",
    "\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(remove_accents(s)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92c2053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(s):\n",
    "    if not s: return []\n",
    "    return normalize_answer(s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2758324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_exact(a_gold, a_pred):\n",
    "    return int(normalize_answer(a_gold) == normalize_answer(a_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf1b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(a_gold, a_pred):\n",
    "    gold_toks = get_tokens(a_gold)\n",
    "    pred_toks = get_tokens(a_pred)\n",
    "    common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    num_same = sum(common.values())\n",
    "    if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "        # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "        return int(gold_toks == pred_toks)\n",
    "    if num_same == 0:\n",
    "        return 0\n",
    "    precision = 1.0 * num_same / len(pred_toks)\n",
    "    recall = 1.0 * num_same / len(gold_toks)\n",
    "    f1 = (2 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb7b15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    test = json.load(open(f\"{base_path}/data/iirc.json\"))\n",
    "    f1s = []\n",
    "    ems = []\n",
    "\n",
    "    for item in tqdm(test):\n",
    "        normalised = [normalize_answer(a.replace('\\n','')) for a in item['responses']]\n",
    "        print(normalised)\n",
    "        c = Counter(normalised)\n",
    "        if len(c.most_common(1)) > 0:\n",
    "            response = c.most_common(1)[0][0]\n",
    "            if \"Not enough information provided in the documents.\" == item['clean_answers'][0]:\n",
    "                item['clean_answers'][0] = \"Not enough information\"\n",
    "            f1 = compute_f1(item['clean_answers'][0], response)\n",
    "        else:\n",
    "            f1 = 0\n",
    "            \n",
    "        f1s.append(f1)\n",
    "        ems.append(compute_exact(item['clean_answers'][0], response))\n",
    "\n",
    "    print(\"F1:\",np.mean(f1s))\n",
    "    print(\"EM:\",np.mean(ems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d964b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ac1c8abcf84ba0973b40f604b67ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b121767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979895a704994652bd37338f40d7dcf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['answervalue yes type binary']\n",
      "['type span answerspans text louis bonaparte passage he rose to prominence under frenchdominated kingdom of holland being appointed minister of justice in 1806 by louis bonaparte type answer start 87 end 103 text napoleon passage and to council of state and as head of court of appeals in hague in 1810 by napoleon type answer start 105 end 114']\n",
      "['type span answerspans text frank mcphee princetonn bernie flowers purduen eddie bell pennsylvanian tom stolhandske texasn tom scott virginian joe collier northwesternn buck martin georgia techn steve mellinger kentuckyn ed luke michigan staten harry babcock georgian passage 1952 college football allamerica team type answer start 1185 end 1459']\n",
      "['type span answerspans text liguria passage university of genoa type answer start 247 end 254']\n",
      "['answervalue 4 type value answerunit years']\n",
      "['answervalue not enough information type text']\n",
      "['not enough information']\n",
      "['type none']\n",
      "['type span answerspans text 4th panchen lama passage 4th panchen lama 15701662 type answer start 98 end 126']\n",
      "['not enough information is provided in document to answer question']\n",
      "['type span answerspans text after 1647 passage monastery of west and was later renamed shankh monastery type answer start 70 end 117']\n",
      "['type none']\n",
      "['answervalue 60 type value answerunit years grand olympic auditorium was 60 years old at time of new regime playing landmark concert there']\n",
      "['type none']\n",
      "['not enough information']\n",
      "['type none']\n",
      "[]\n",
      "['type none']\n",
      "['type none']\n",
      "['type none']\n",
      "['not enough information']\n",
      "['type none']\n",
      "[]\n",
      "['based on above documents there is no clear evidence as to why president trump fired fbi director james comey however lichtmans comments suggest that comeys firing and circumstantial evidence of 2016 election coordination between trump campaign and russia were reasons for impeachment trump was reportedly frustrated that comey would not publicly confirm that president was not personally under investigation']\n",
      "[]\n",
      "['type span answerspans text not enough information passage not found type answer']\n",
      "['answervalue not enough information type text']\n",
      "['not enough information']\n",
      "['answervalue not enough information type text answerunit']\n",
      "['type none']\n",
      "['type span answerspans text not enough information passage evidence type answer start 0 end 19']\n",
      "['type none']\n",
      "[]\n",
      "['type span answerspans noanswer true']\n",
      "[]\n",
      "['not enough information']\n",
      "['answervalue not enough information type text']\n",
      "['type span answerspans text not enough information passage document 4 type answer start 0 end 18']\n",
      "['type span answerspans text not enough information']\n",
      "['type span answerspans text not enough information passage document 4 type answer']\n",
      "[]\n",
      "['type none']\n",
      "['type span answerspans text harpers magazine passage harpers magazine type answer start 31 end 48']\n",
      "['answervalue not enough information type text']\n",
      "['not enough information']\n",
      "['answervalue not enough information type text']\n",
      "['type span answerspans text not enough information passage document 4 title pennsylvania route 41 content pa 41 begins at delaware border in kennett township chester county where road continues into that state as de 41 and heads towards wilmington from state line route heads northwest on twolane undivided gap newport pike passing through farmland with some development road enters new garden township and comes to interchange with limestone road which heads south to delaware border and becomes de 7 pa 41 continues northwest through more rural areas with some homes and businesses crossing newark road and passing weigh station on southbound side that serves trucks from both directions then route heads into borough of avondale where it crosses east penn railroad line and comes to intersection with baltimore pike here road becomes pennsylvania avenue and passes through wooded residential areas pa 41 leaves avondale for london grove township and becomes gap newport pike again passing near homes and farmland before baltimore pike heads to west route continues through commercial areas before coming to interchange with us 1 freeway type answer start 0 end 15']\n",
      "['final score of game between suns and indiana pacers on january 14 is not provided in documents']\n",
      "['type none']\n",
      "['not enough information']\n",
      "F1: 0.05775700994021334\n",
      "EM: 0.0\n"
     ]
    }
   ],
   "source": [
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2746823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
