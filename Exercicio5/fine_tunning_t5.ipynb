{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "744bf9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    TrainerCallback,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    get_cosine_with_hard_restarts_schedule_with_warmup,\n",
    "    Seq2SeqTrainer\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ftfy\n",
    "import evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d997f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 't5-base'\n",
    "model_folder = \"model\"\n",
    "model_name = \"t5_doc2query\"\n",
    "base_path = \".\"\n",
    "batch_size = 6\n",
    "checkpoints_path = \"checkpoints\"\n",
    "gradient_accumulation_steps = 8\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f412af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    colnames = [\"query\", \"relevant\", \"not relevant\"]\n",
    "    df_data = pd.read_csv(f\"{base_path}/data/msmarco_triples.train.tiny.tsv\", encoding=\"UTF=8\", sep=\"\\t\", names=colnames)\n",
    "    \n",
    "    df_data[\"relevant\"] = df_data[\"relevant\"].apply(lambda text: ftfy.fix_text(text))\n",
    "    df_data = df_data.drop(\"not relevant\", axis=1)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5d74755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    df_train, df_val = train_test_split(\n",
    "        df,\n",
    "        test_size=0.10,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    return df_train, df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "038c96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2QueryDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ms_df, tokenizer):\n",
    "        self.tokenized_topics = tokenizer(ms_df['query'].tolist(), return_length=True)\n",
    "        self.tokenized_passage = tokenizer(ms_df['relevant'].tolist(), return_length=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_topics['input_ids'])\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {\n",
    "            'input_ids': self.tokenized_passage['input_ids'][index],\n",
    "            'attention_mask': self.tokenized_passage['attention_mask'][index],\n",
    "            'labels': self.tokenized_topics['input_ids'][index]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1baba14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2QueryTrainerCallback(TrainerCallback):\n",
    "    def __init__(self, best_validation_yet=99999, model=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.best_validation_metric = best_validation_yet\n",
    "        self.model = model\n",
    "\n",
    "\n",
    "    def on_evaluate(self, args, state, control, model=None, metrics=None, **kwargs):\n",
    "        print(\"metrics['eval_loss']={}\".format(metrics['eval_loss']))\n",
    "        print(\"metrics['eval_bleu']={}\".format(metrics['eval_bleu']))\n",
    "\n",
    "\n",
    "        if metrics['eval_bleu'] > self.best_validation_metric:\n",
    "            self.model.save_pretrained(\n",
    "                os.path.join(\n",
    "                    checkpoints_path,\n",
    "                    \"checkpoint-{}-{:.4f}\".format(\n",
    "                        state.global_step,\n",
    "                        metrics['eval_bleu']\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "\n",
    "            self.best_validation_metric = metrics['eval_bleu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "346b45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_set(train_df, validation_df, tokenizer):\n",
    "    train_dataset = Doc2QueryDataset(train_df, tokenizer)\n",
    "    eval_dataset = Doc2QueryDataset(validation_df, tokenizer)\n",
    "    \n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ebd617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dececa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    metric = evaluate.load(\"sacrebleu\")\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    print(\"compute_metrics. preds.shape={}\".format(preds.shape))\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    \n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcdbd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tokenizer, model, train_dataset, eval_dataset):\n",
    "    training_params = Seq2SeqTrainingArguments(\n",
    "        output_dir=checkpoints_path,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=200,\n",
    "        save_strategy='steps',\n",
    "        save_steps=1000,\n",
    "        logging_strategy='steps',\n",
    "        logging_steps=10,\n",
    "        save_total_limit=2,\n",
    "        dataloader_pin_memory=True,\n",
    "        predict_with_generate=True,\n",
    "        generation_num_beams=10,\n",
    "        fp16=True\n",
    "    )\n",
    "    \n",
    "    label_pad_token_id = -100\n",
    "\n",
    "    data_collator = DataCollatorForSeq2Seq(\n",
    "        tokenizer,\n",
    "        model=model,\n",
    "        label_pad_token_id=label_pad_token_id,\n",
    "        pad_to_multiple_of=8 if training_params.fp16 else None,\n",
    "    )\n",
    "    \n",
    "    trainer_callback = Doc2QueryTrainerCallback(\n",
    "        best_validation_yet=-1,\n",
    "        model=model\n",
    "    )\n",
    "    \n",
    "    num_training_steps = epochs * int(len(train_dataset) // (batch_size * gradient_accumulation_steps))\n",
    "\n",
    "    optimzer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-3)\n",
    "    scheduler = get_cosine_with_hard_restarts_schedule_with_warmup(\n",
    "        optimzer,\n",
    "        0,\n",
    "        num_training_steps,\n",
    "        num_cycles=10\n",
    "    )\n",
    "    \n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_params,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[trainer_callback],\n",
    "        optimizers=(optimzer, scheduler),\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9a2a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685b13e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = split_data(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2de8ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoel/anaconda3/envs/unicamp/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f02f0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, eval_dataset = load_data_set(df_train, df_val, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abda3d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20600' max='20600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20600/20600 13:36:13, Epoch 99/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.762500</td>\n",
       "      <td>1.540922</td>\n",
       "      <td>19.919200</td>\n",
       "      <td>9.802700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.482500</td>\n",
       "      <td>1.511125</td>\n",
       "      <td>20.412700</td>\n",
       "      <td>9.872700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.278400</td>\n",
       "      <td>1.509185</td>\n",
       "      <td>20.296800</td>\n",
       "      <td>9.657300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.133600</td>\n",
       "      <td>1.500389</td>\n",
       "      <td>21.009700</td>\n",
       "      <td>9.746400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.296400</td>\n",
       "      <td>1.668191</td>\n",
       "      <td>17.565600</td>\n",
       "      <td>9.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.318200</td>\n",
       "      <td>1.662287</td>\n",
       "      <td>17.188700</td>\n",
       "      <td>9.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.223500</td>\n",
       "      <td>1.648296</td>\n",
       "      <td>16.483500</td>\n",
       "      <td>9.913600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.263900</td>\n",
       "      <td>1.646380</td>\n",
       "      <td>16.119900</td>\n",
       "      <td>9.960900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.251900</td>\n",
       "      <td>1.646291</td>\n",
       "      <td>16.015800</td>\n",
       "      <td>9.984500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.265400</td>\n",
       "      <td>1.647350</td>\n",
       "      <td>16.010300</td>\n",
       "      <td>9.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.249000</td>\n",
       "      <td>1.647387</td>\n",
       "      <td>16.010300</td>\n",
       "      <td>9.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>1.240200</td>\n",
       "      <td>1.647315</td>\n",
       "      <td>16.010300</td>\n",
       "      <td>9.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>1.284000</td>\n",
       "      <td>1.647184</td>\n",
       "      <td>16.010300</td>\n",
       "      <td>9.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>1.333400</td>\n",
       "      <td>1.647038</td>\n",
       "      <td>16.016200</td>\n",
       "      <td>9.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.241200</td>\n",
       "      <td>1.647078</td>\n",
       "      <td>16.016200</td>\n",
       "      <td>9.976400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>1.278900</td>\n",
       "      <td>1.647096</td>\n",
       "      <td>16.026300</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>1.253400</td>\n",
       "      <td>1.647035</td>\n",
       "      <td>16.029600</td>\n",
       "      <td>9.974500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>1.410200</td>\n",
       "      <td>1.646985</td>\n",
       "      <td>16.059200</td>\n",
       "      <td>9.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>1.358200</td>\n",
       "      <td>1.646944</td>\n",
       "      <td>16.059200</td>\n",
       "      <td>9.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.235400</td>\n",
       "      <td>1.646944</td>\n",
       "      <td>16.059200</td>\n",
       "      <td>9.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>1.266800</td>\n",
       "      <td>1.646972</td>\n",
       "      <td>16.059200</td>\n",
       "      <td>9.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>1.280600</td>\n",
       "      <td>1.646982</td>\n",
       "      <td>16.059200</td>\n",
       "      <td>9.971800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>1.282800</td>\n",
       "      <td>1.646945</td>\n",
       "      <td>16.047300</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>1.241700</td>\n",
       "      <td>1.646946</td>\n",
       "      <td>16.047300</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.247400</td>\n",
       "      <td>1.646961</td>\n",
       "      <td>16.047300</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>1.272500</td>\n",
       "      <td>1.646984</td>\n",
       "      <td>16.046000</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>1.287200</td>\n",
       "      <td>1.646961</td>\n",
       "      <td>16.046000</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>1.208700</td>\n",
       "      <td>1.646876</td>\n",
       "      <td>16.046000</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>1.265500</td>\n",
       "      <td>1.646926</td>\n",
       "      <td>16.046000</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.317000</td>\n",
       "      <td>1.646926</td>\n",
       "      <td>16.046000</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>1.266300</td>\n",
       "      <td>1.646926</td>\n",
       "      <td>16.046000</td>\n",
       "      <td>9.973600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>1.279300</td>\n",
       "      <td>1.646936</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>1.408400</td>\n",
       "      <td>1.646845</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>1.196900</td>\n",
       "      <td>1.646863</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.263200</td>\n",
       "      <td>1.646883</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>1.275800</td>\n",
       "      <td>1.646859</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>1.244300</td>\n",
       "      <td>1.646784</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>1.242700</td>\n",
       "      <td>1.646751</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>1.264600</td>\n",
       "      <td>1.646741</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.269700</td>\n",
       "      <td>1.646731</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>1.362700</td>\n",
       "      <td>1.646731</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>1.346400</td>\n",
       "      <td>1.646720</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>1.259600</td>\n",
       "      <td>1.646665</td>\n",
       "      <td>16.040100</td>\n",
       "      <td>9.975500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>1.266900</td>\n",
       "      <td>1.646642</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.254700</td>\n",
       "      <td>1.646531</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>1.246900</td>\n",
       "      <td>1.646595</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>1.303100</td>\n",
       "      <td>1.646512</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>1.267700</td>\n",
       "      <td>1.646504</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>1.267800</td>\n",
       "      <td>1.646511</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.251500</td>\n",
       "      <td>1.646433</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>1.213500</td>\n",
       "      <td>1.646433</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>1.349500</td>\n",
       "      <td>1.646433</td>\n",
       "      <td>16.038800</td>\n",
       "      <td>9.977300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.5409224033355713\n",
      "metrics['eval_bleu']=19.9192\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.511125087738037\n",
      "metrics['eval_bleu']=20.4127\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.5091851949691772\n",
      "metrics['eval_bleu']=20.2968\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.5003886222839355\n",
      "metrics['eval_bleu']=21.0097\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6681907176971436\n",
      "metrics['eval_bleu']=17.5656\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6622869968414307\n",
      "metrics['eval_bleu']=17.1887\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6482958793640137\n",
      "metrics['eval_bleu']=16.4835\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646379828453064\n",
      "metrics['eval_bleu']=16.1199\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6462910175323486\n",
      "metrics['eval_bleu']=16.0158\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6473501920700073\n",
      "metrics['eval_bleu']=16.0103\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6473865509033203\n",
      "metrics['eval_bleu']=16.0103\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6473146677017212\n",
      "metrics['eval_bleu']=16.0103\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.647183895111084\n",
      "metrics['eval_bleu']=16.0103\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6470381021499634\n",
      "metrics['eval_bleu']=16.0162\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6470775604248047\n",
      "metrics['eval_bleu']=16.0162\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.647096037864685\n",
      "metrics['eval_bleu']=16.0263\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6470354795455933\n",
      "metrics['eval_bleu']=16.0296\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469850540161133\n",
      "metrics['eval_bleu']=16.0592\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469435691833496\n",
      "metrics['eval_bleu']=16.0592\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469435691833496\n",
      "metrics['eval_bleu']=16.0592\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469720602035522\n",
      "metrics['eval_bleu']=16.0592\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469815969467163\n",
      "metrics['eval_bleu']=16.0592\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469448804855347\n",
      "metrics['eval_bleu']=16.0473\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469460725784302\n",
      "metrics['eval_bleu']=16.0473\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469610929489136\n",
      "metrics['eval_bleu']=16.0473\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469838619232178\n",
      "metrics['eval_bleu']=16.046\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6469610929489136\n",
      "metrics['eval_bleu']=16.046\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6468756198883057\n",
      "metrics['eval_bleu']=16.046\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646925687789917\n",
      "metrics['eval_bleu']=16.046\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646925687789917\n",
      "metrics['eval_bleu']=16.046\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646925687789917\n",
      "metrics['eval_bleu']=16.046\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646936058998108\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6468448638916016\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646862506866455\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6468825340270996\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.646859049797058\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6467835903167725\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6467511653900146\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6467410326004028\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6467311382293701\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6467311382293701\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6467196941375732\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6466646194458008\n",
      "metrics['eval_bleu']=16.0401\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6466424465179443\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6465306282043457\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6465948820114136\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6465119123458862\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6465044021606445\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6465109586715698\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6464333534240723\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6464333534240723\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=1.6464333534240723\n",
      "metrics['eval_bleu']=16.0388\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n",
      "compute_metrics. preds.shape=(1100, 20)\n",
      "metrics['eval_loss']=nan\n",
      "metrics['eval_bleu']=0.0195\n"
     ]
    }
   ],
   "source": [
    "train(tokenizer, model, train_dataset, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c2bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
